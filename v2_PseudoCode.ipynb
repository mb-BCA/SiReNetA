{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-code discussion towards v2\n",
    "\n",
    "Authors: **Gorka Zamora-López** and **Matthieu Gilson**\n",
    "\n",
    "---------------------\n",
    "\n",
    "The goal of this notebook is to try, propose and discuss how we would like that typical workflows look like in the object-oriented version of *SiReNetA* (v2). The notebook is based on the workflow described in the first tutorial [notebook](https://github.com/mb-BCA/SiReNetA_Tutorials/blob/master/Tutorial_Notebooks/1_GettingStarted.ipynb).\n",
    "\n",
    "See also further discussions in the [TODO_Future.md](https://github.com/mb-BCA/SiReNetA/blob/v1_dev/TODO_Future.md) file.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard & third-party library imports\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sireneta as sna\n",
    "print( 'SiReNetA:', sna.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting options to control visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the options from a local file\n",
    "from plot_specs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the network determined by the following binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample graph to study\n",
    "net = np.loadtxt('../Data/Testnet_N8.txt', dtype=int)\n",
    "# Number of nodes\n",
    "N = len(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence of the leaky-cascade model depends on the leakage time-constant, when $\\tau \\leq 1 \\,/\\, \\lambda_{max}$. Find the largest eigenvalue of connectivity *A* and the critical $\\tau_{max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest eigenvalue of the connectivity matrix A\n",
    "evs = np.linalg.eigvals(net)\n",
    "evmax = evs.real.max()\n",
    "# Calculate the largest possible tau\n",
    "taumax = 1.0 / evmax\n",
    "\n",
    "print( f'Spectral radius:\\t{evmax:2.5f}' )\n",
    "print( f'Largest possible tau:\\t{taumax:2.5f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Initialize the main container object (instance)\n",
    "\n",
    "Object `Rmats` must be initialized with two mandatory parameters:\n",
    "\n",
    "* `con` : The connectivity matrix.\n",
    "* `canmod` : identifier for the canonical model. Probably a string.\n",
    "\n",
    "These two parameters shall be **_unmutable_**. They cannot be changed after object creation. `con` will be a connectivity matrix, either loaded from data or generated with some graph library.\n",
    "\n",
    "\n",
    "> WARNING ! `con` is likely to be generated by a graph analysis software, or loaded from data as \n",
    "\n",
    "**Gorka**: I don't think we need to initialize `Rmats` with more parameters.\n",
    "\n",
    "TODO : Probably, find a better name for the creation function `PairWiseResp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rmat must be initialized for a connectivity matrix and a canonical model.\n",
    "# These are unmutable and cannot be changed. Ever !\n",
    "Rmats = sna.PairWiseResp(con=net.T, canmod='LeakyCascade')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, `Rmats` should also *know* whether `con` is directed or undirected and the number of nodes *N*. E.g.:\n",
    "\n",
    "``` python\n",
    ">>> Rmats.N\n",
    "8\n",
    ">>> Rmats.directed\n",
    "False\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the conditions and compute the pair-wise responses\n",
    "\n",
    "For now, I see two ways in which the needed metadata could be inputed into the `Rmats` object and compute the pair-wise responses.\n",
    "\n",
    "----------------------\n",
    "\n",
    "### Option 1: Feed `Rmats` with parameters and then call the calculation of $\\mathcal{R}_{ij}(t)$.\n",
    "In this option, the `Rmats` object is first populated with all the parameters needed for the \"simulation\" (feed the necessary attributes) and then the pair-wise responses are calculated.\n",
    "\n",
    "1. Feed the different parameters (attributes) to `Rmats`, e.g.:\n",
    "    - `Rmats.max = 10`\n",
    "    - `Rmats.tau = 0.8 * taumax`\n",
    "    - ...\n",
    "2. Calculate the pairwise responses `Rmats.Calc_Resp()`\n",
    "\n",
    "I think this is quite a traditional way, although not my favourite choice (Gorka) because it is not flexible in case the \"simulation\" needs to be run again, e.g. because the `tmax` was not long enough and responses didn't converge enough. See *Option 2* and the discussion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "Rmats.tmax = 10\n",
    "Rmats.timestep = 0.01\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "# NOTE: Actually, `taumax` should also be an attribute of Rmats, right?\n",
    "Rmats.tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "# Example of stimulus on one node\n",
    "Rmats.S0 = np.zeros(N)\n",
    "Rmats.S0[0] = 1.0\n",
    "\n",
    "# Example of all nodes receive same stimulus\n",
    "Rmats.S0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal evolution of the pair-wise responses R(t)\n",
    "Rmats.Calc_Resp(case='regressed') \n",
    "\n",
    "\n",
    "# Print some feedback\n",
    "print( Rmats.tfinal, Rmats.dt, Rmats.nsteps )\n",
    "print( Rmats.tpoints )\n",
    "print( len(Rmats.tpoints) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this option, all the parameters needed for the \"simulation\" have been already stored as attributes of `Rmats`, before calling the `Calc_Resp()` function.\n",
    "These are: `S0`, `tmax`, `timestep` and `tau`. Parameter `case` is rather optional and only available in two of the five canonical models. `case` could be stored before calling the function, or added as an attribute to `Rmats` at function call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "### Option 2: Define the parameters externally, and then call the calculation of $\\mathcal{R}_{ij}(t)$.\n",
    "In this option, the \"simulation\" parameters are defined in a more traditional way (non-OO). The parameters are defined and explicitly entered into the `Calc_Resp()` function. It is only when `Calc_Resp()` is called, that the attributes of `Rmats` are populated or updated.\n",
    "\n",
    "1. Feed the different parameters (attributes) to `Rmats`, e.g.:\n",
    "    - `tfinal = 10 10`\n",
    "    - `dt = 0.01` \n",
    "    - `tau = 0.8 * taumax`\n",
    "    - `stimvec = np.ones(N)` \n",
    "2. Calculate the pairwise responses `Rmats.Calc_Resp(S0=stimvec, tmax=tfinal, timestep=dt, case='regressed')`.\n",
    "\n",
    "I think this is quite a traditional way, although not my favourite choice (Gorka) because it is not flexible in case the \"simulation\" needs to be run again, e.g. because the `tmax` was not long enough and responses didn't converge enough. See *Option 2* and the discussion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "tfinal = 10\n",
    "dt = 0.01\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "stimvec = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal evolution of the pair-wise responses R(t)\n",
    "## Here, all necessary \"simulation\" parameters (`S0`, `tmax`, `timestep` and `tau`)\n",
    "## shall be manually entered. `case`is an optional parameter.\n",
    "Rmats.calc_Resp(S0=stim, tau=tau, tmax=tfinal, timestep=dt, case='regressed')\n",
    "\n",
    "\n",
    "# Print some feedback\n",
    "print( Rmats.tfinal, Rmats.dt, Rmats.nsteps )\n",
    "print( Rmats.tpoints )\n",
    "print( len(Rmats.tpoints) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this option, the crucial parameters needed for the \"simulation\" (`S0`, `tmax`, `timestep` and `tau`) need to be entered to `Calc_Resp()` explicitely. Then, when the function is called, the function fills or updates those attributes into `Rmats` object. \n",
    "\n",
    "Q : Actually, is there a way in Python to prevent that a user externally updates attributes `S0`, `tmax`, `timestep` and `tau`, and that these can **only** be updated from inside `Calc_Resp()` function ? That would make things pretty safe.\n",
    "\n",
    "----------------------\n",
    "\n",
    "**Gorka** : Why do I prefer this option? I think it is safer that the crucial metadata will not be changed accidentally by the user or anything else. For example, attribures `tmax` and `timestep` are not directly modified by the user, but are only updated when calling the `Calc_Resp()` function. \n",
    "\n",
    "Imagine we compute the responses for tmax = 10 and timestep = 0.1. We plot the result and realize that this temporal scale is too large. We want to recalculate the responses (without having to initialize a new instance) for tmax = 1.0 and timestep=0.001.\n",
    "In Option-1 that would mean to edit manually the attributes `Rmats.tmax=1.0` and `Rmats.timestep=0.001`. Then, we have to deliberatelly call again `Rmats.Calc_Resp()` in order to update the results. But, what if the user, after changing `tmax` and `timestep` attributes, forget to call `Calc_Resp()` ? In that case, the metadata of `Rmats` does no longer match the one used to previously compute the responses, whose result is still saved into an array of shape (10//0.1+1,N,N), instead of the (1.0//0.001+1,N,N) now expected. This situation might not be very usual when scripting but … I can easily see things like this happening when working on Jupyter Notebooks.\n",
    "\n",
    "In Option-2, the only time that attributes are allowed to change are at the call of `Calc_Resp()` function, and only this function has the permission to change them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of `Calc_Resp()` function\n",
    "\n",
    "The main result of `Calc_Resp()` function (method) is to compute the response matrices over time. This is stored into a 3D numpy array `data` of shape (tmax//dt+1, N, N). The \"+1\" is because the first time step is *t=0*. All subsequent results are obtained out of `Rmats.data`, either slicing the 3D array projecting along different axes, or by estimating metrics out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some results\n",
    "\n",
    "For example, visualize the response matrices at selected time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the pair-wise response matrices at times t = 0.1, 0.3, 0.5, 1.0, 2.0, 3.0\n",
    "maxresp = Rmats.max()\n",
    "\n",
    "tidxlist = [10,20,50,100,200,500]\n",
    "plt.figure(figsize=[12,6])\n",
    "for i, tidx in enumerate(tidxlist):\n",
    "    t = tpoints[tidx]\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.title( f'$\\mathcal{{R}}(t)$ matrix at t={t:1.1f}' )\n",
    "    plt.imshow(Rmats.data[tidx], cmap=new_Reds)\n",
    "    \n",
    "    plt.clim(0,maxresp)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.yticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.xlabel( 'source node' )\n",
    "    plt.ylabel( 'target node' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few response curves. \n",
    "# The responses of i = 2, ..., N to the stimulus at j = 1.\n",
    "\n",
    "plt.figure(figsize=(6.4,3))\n",
    "for i in range(1,N):\n",
    "    plt.plot(Rmats.tpoints, Rmats.data[:,i,0], label=f'1 $\\\\to$ {i+1}')\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "plt.ylabel( 'Pair-wise Response' )\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Slicing and projecting `Rmats.data`. Extracting metrics.\n",
    "\n",
    "I have a major doubt here. After the tensor containing $\\mathcal{R}_{ij}(t)$, the other two time-series \"arrays\" are the global response $R(t)$ and the pair-wise responses $r_i(t)$. `Rglob` is a 1D ndarray of length `nsteps`, while `rnodes` is a 2D ndarray of shape (`nsteps`,`N`).\n",
    "\n",
    "The question is whether `Rglob` and `rnodes` should be considered as:\n",
    "1. two independent objects which inherit the temporal attributes from `Rmats`, and the methods (e.g., `Time2Peak()` and `AreaUnderCurve()`) or \n",
    "2. attributes of `Rmats`. Q: Can attributes be objects themselves, that share selected attributes?  \n",
    "\n",
    "GORKA : Personally, I have a slight preference for the first possibility because that would allow me to keep the the workflows closer to what I am used to. But I ignore the details of what would be easier and more consistent to code internally, given that functions like `AreaUnderCurve()` and `Time2Peak()` do apply to all the 3D, 2D and 1D time-series tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider them **as independent objects**, we would for example do as follows. These  function calls (even in the form of methods) they will create and return a new object instance. Not same object class as `Rmats` but similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global network response\n",
    "## `Rglob` is an object which, at time of creation inherits `tpoints` and `dt`\n",
    "Rglob = Rmats.GlobalResponse()  # or\n",
    "Rglob = sna.GlobalResponse(Rmats)\n",
    "print( Rglob.data.shape() )  # `data` is the 1D array\n",
    "print( Rglob.shape() )       # Would that be legal ?\n",
    "print( Rglob.nsteps )\n",
    "\n",
    "# Plot the global response curve, r(t)\n",
    "plt.figure()\n",
    "plt.plot(Rglob.tpoints, Rglob.data)\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "\n",
    "\n",
    "# Calculate some further results\n",
    "totRglob = Rglob.AreaUnderCurve()  # Already knows `dt`, inherited it \n",
    "totRglob = sna.AreaUnderCurve(Rmats)  # ?\n",
    "\n",
    "ttp_Rglob = Rglob.Time2Peak()      # Already knows `dt`, inherited it \n",
    "ttp_Rglob = sna.Time2Peak(Rglob)   # ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the node-wise responses\n",
    "## `rnodes` is an object which, at time of creation inherits `tpoints` and `dt`\n",
    "if Rmats.directed:\n",
    "    inr_nodes, outr_nodes = Rmats.NodeResponses(selfresp=True)\n",
    "else: \n",
    "    r_nodes = Rmats.NodeResponses(selfresp=True)\n",
    "\n",
    "# Plot all the node responses\n",
    "plt.figure()\n",
    "for i in range(N):\n",
    "    plt.plot(inr_nodes.tpoints, inr_nodes.data[i])\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "\n",
    "\n",
    "# Compute the total node responses\n",
    "totinr_nodes = inr_nodes.AreaUnderCurve()\n",
    "totoutr_nodes = outr_nodes.AreaUnderCurve()\n",
    "\n",
    "print( totinr_nodes.data.shape )   # `data` is the 2D array\n",
    "print( totinr_nodes.shape )        # Would this be legal ?\n",
    "\n",
    "\n",
    "# Calculate time-to-peak for the node responses\n",
    "## Ok, here ttp_inr and ttp_outr are 1D arrays of length N.\n",
    "## As just arrays, they loose any metadata associated to the nodes, e.g., `labels`.\n",
    "ttp_inr = inr_nodes.Time2Peak()\n",
    "ttp_outr = inr_nodes.Time2Peak()\n",
    "\n",
    "print( ttp_inr, ttp_outr )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider them **as attributes of the `Rmats` object**, then we may just need to call the methods, without assignment. The first time called, they will do the calculation and create the corresponding array, saved within the `Rmats` container. The second time we call these methods, `Rmats` should already know the data is there and read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global network response\n",
    "## `Rglob` is an object which, at time of creation inherits `tpoints` and `dt`\n",
    "Rmats.GlobalResponse()\n",
    "\n",
    "print( Rmats.GlobalResponse().shape )  # `Rmats.GlobalResponse() is now a 1D array.\n",
    "print( Rmats.nsteps )\n",
    "\n",
    "\n",
    "# Plot the global response curve, r(t)\n",
    "plt.figure()\n",
    "plt.plot(Rmats.tpoints, Rmats.GlobalResponse())\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "\n",
    "\n",
    "# Calculate some further results\n",
    "## `totGlobalResonse()` is a method of `Rmats` which, internally, \n",
    "## calls `AreaUnderCurve()` and applies to the data saved in `Rmats.GlobalResponse()\n",
    "Rmats.totGlobalResponse()   \n",
    "## `totTime2Peak() is a method of `Rmats` which, internally, \n",
    "## calls `Time2Peak()` and applies to the data saved in `Rmats.GlobalResponse()\n",
    "Rmats.totTime2Peak()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These last start to look pretty ugly. Probably is going to be worse for the node responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the node-wise responses\n",
    "Rmats.NodeResponses(selfresp=True)\n",
    "\n",
    "## How to deal in this case with the possiblity of having both \n",
    "## the input and the output node responses? For example ... ?\n",
    "print( Rmats.NodeResponses()['in'].shape )  # ??\n",
    "print( Rmats.NodeResponses()['out'].shape )  # ??\n",
    "\n",
    "\n",
    "# Plot all the node responses\n",
    "plt.figure()\n",
    "for i in range(N):\n",
    "    plt.plot( Rmats.tpoints, Rmats.NodeResponses()['in'][i] )  # Jeez, that looks ugly!!\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "\n",
    "\n",
    "# Compute the total node responses\n",
    "Rmats.totNodeResponses()\n",
    "\n",
    "print( Rmats.totNodeResponses()['in'].shape )\n",
    "print( Rmats.totNodeResponses()['out'].shape )\n",
    "\n",
    "\n",
    "# Calculate time-to-peak for the node responses\n",
    "Rmats.nodeTime2Peak()\n",
    "\n",
    "print( Rmats.nodeTime2Peak()['in'], Rmats.nodeTime2Peak()['in'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok ... all these looks pretty ugly and complicated. It seems that generating new independent object instances when e.g., `AreaUnderCurve()` or `Time2Peak()` are called, is the better option, despite it might be a waste of memory that each array has to remember some redundant metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
