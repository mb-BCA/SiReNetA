{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-code discussion towards v2\n",
    "\n",
    "Authors: **Gorka Zamora-López** and **Matthieu Gilson**\n",
    "\n",
    "---------------------\n",
    "\n",
    "The goal of this notebook is to try, propose and discuss how we would like that typical workflows look like in the object-oriented version of *SiReNetA* (v2). The notebook is based on the workflow described in the first tutorial [notebook](https://github.com/mb-BCA/SiReNetA_Tutorials/blob/master/Tutorial_Notebooks/1_GettingStarted.ipynb).\n",
    "\n",
    "See also further discussions in the [TODO_Future.md](https://github.com/mb-BCA/SiReNetA/blob/v1_dev/TODO_Future.md) file.\n",
    "\n",
    "----------------------\n",
    "\n",
    "#### Philosophy for user interfacing\n",
    "\n",
    "We want that the library avoids some obvious possible errors from user, or crucial parameters to be altered accidentally. BUT, in general we want the workflows to require users to know what they are doing, at every step. In some situations, it would be easier to have the code to do some calculations for the user internally or specify some parameters for them. That could be safer sometimes and lead to shorter workflows, but this is also black-box-like. And we don't want that. The user has to be aware of the steps needed to calculate something, and request them explicitly, one-by-one. So, the code will only calculate what the user asks, at every step.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiReNetA: 1.0.0.dev1\n"
     ]
    }
   ],
   "source": [
    "# Python standard & third-party library imports\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sireneta as sna\n",
    "print( 'SiReNetA:', sna.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting options to control visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the options from a local file\n",
    "from plot_specs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the network determined by the following binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample graph to study\n",
    "net = np.loadtxt('../Data/Testnet_N8.txt', dtype=int)\n",
    "# Number of nodes\n",
    "N = len(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence of the leaky-cascade model depends on the leakage time-constant, when $\\tau \\leq 1 \\,/\\, \\lambda_{max}$. Find the largest eigenvalue of connectivity *A* and the critical $\\tau_{max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest eigenvalue of the connectivity matrix A\n",
    "evs = np.linalg.eigvals(net)\n",
    "evmax = evs.real.max()\n",
    "# Calculate the largest possible tau\n",
    "taumax = 1.0 / evmax\n",
    "\n",
    "print( f'Spectral radius:\\t{evmax:2.5f}' )\n",
    "print( f'Largest possible tau:\\t{taumax:2.5f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Initialize the main container object (instance)\n",
    "\n",
    "Object `Rmats` must be initialized with three mandatory parameters:\n",
    "\n",
    "* `con` : The connectivity matrix.\n",
    "* `orientation` : specify whether `con` is based on graph analysis convention ($A_{ij}=1$ means $i \\to j$) or the dynamical systems convention ($A_{ij}=1$ means $j \\to i$). Accepted values: 'ij' or 'ji'.\n",
    "* `model` : identifier for the canonical model. Accepted values are strings, representative of the canonical model.\n",
    "\n",
    "These three parameters shall be **_unmutable_**. They cannot be changed after object creation. `con` will be a connectivity matrix, either loaded from data or generated with some graph library.\n",
    "\n",
    "\n",
    "TODO : Maybe, a better name for the instance creation function (class name) `PairWiseResp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rmat must be initialized for a connectivity matrix and a canonical model.\n",
    "# These are unmutable and cannot be changed after creation.\n",
    "Rmats = sna.PairWiseResp(con=net, orientation='ij', model='LeakyCascade', [optional_params ...] )\n",
    "\n",
    "# Is this maybe more correct, as for functions?\n",
    "Rmats = sna.PairWiseResp(net, 'ij', 'LeakyCascade', [optional_params ...] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, `Rmats` should also *know* whether `con` is directed or undirected and the number of nodes *N*. E.g.:\n",
    "\n",
    "``` python\n",
    ">>> Rmats.N\n",
    "8\n",
    ">>> Rmats.directed\n",
    "False\n",
    "\n",
    "```\n",
    "\n",
    "These should be evaluated internally, at time of instance generation. \n",
    "\n",
    "> **DIRECTED / SYMMETRIC** : Or shall we request the user to specify if the network is directed (weighted asymmetric) as a fourth mandatory argument? Even if we do so, at instance initialization we should verify that info. It is important because later, the node-wise responses will return one array for undirected / weighted-symmetric `con` and two array (input and output responses) for directed / weighted-asymmetric `con`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enter (needed) parameters and compute the pair-wise responses\n",
    "\n",
    "We would do this by first populating the `Rmats` object with all the parameters needed for the \"simulation\" (feed them as attributes) and then the pair-wise responses are calculated.\n",
    "\n",
    "1. Feed the different parameters (attributes) to `Rmats`, e.g.:\n",
    "    - `Rmats.tfinal = 10`\n",
    "    - `Rmats.dt = 0.01`\n",
    "    - `Rmats.tau = 0.8 * taumax`\n",
    "    - ...\n",
    "2. Calculate the pairwise responses calling method : `Rmats.Calc_Resp()` .\n",
    "\n",
    "I think this is the typical workflow for, e.g. TVB, right? In script or nb, this should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "Rmats.tfinal = 10\n",
    "Rmats.dt = 0.01\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "# NOTE: Actually, `taumax` could also be an attribute of Rmats, (for the Leaky-Cascade)\n",
    "Rmats.tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "# Example of stimulus on one node\n",
    "Rmats.S0 = np.zeros(N)\n",
    "Rmats.S0[0] = 1.0\n",
    "\n",
    "# Example of all nodes receive same stimulus\n",
    "Rmats.S0 = 1.0\n",
    "\n",
    "# Decide which output version we want for the leaky-cascade model\n",
    "Rmats.case = 'regressed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, calculate the temporal evolution of the pair-wise responses R(t)\n",
    "Rmats.Calc_Resp() \n",
    "# ... this will take time ...\n",
    "\n",
    "\n",
    "# And, print some feedback\n",
    "print( Rmats.tfinal, Rmats.dt, Rmats.nsteps )\n",
    "print( Rmats.tpoints )\n",
    "print( len(Rmats.tpoints), Rmats.nsteps )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, all the parameters needed for the \"simulation\" have been already stored as attributes of `Rmats`, before calling the `Calc_Resp()` function. These are: `S0`, `tmax`, `dt` and `tau`. Parameter `case` is only available in the 'LeakyCascade' and the 'ContDiffusion' canonical models. \n",
    "\n",
    "Alternative, could we have a hybrid possibility such that the parameters could be entered either as attributes before calling `Calc_Resp()` method, and as parameters to `Calc_resp()` ? Imagine the following situation in which we define a few parameters before, but then override add `dt` and `case` at method call. For example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "Rmats.tfinal = 10\n",
    "Rmats.dt = 0.1\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "Rmats.tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "Rmats.S0 = 1.0\n",
    "\n",
    "# Finally, calculate the temporal evolution of the pair-wise responses R(t)\n",
    "Rmats.Calc_Resp(dt=0.01, case='regressed') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this possible, safe and reasonable? Would allowing this make the code more complicated?\n",
    "If this were an option, the parameters introduced here \"by hand\" willoverride any previous value `Rmats` had for these attributes such that if, after running `Calc_Resp()` we will obtain:\n",
    "\n",
    "``` python\n",
    ">>> Rmats.dt\n",
    "0.01\n",
    ">>> Rmats.case\n",
    "regressed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of `Calc_Resp()` function\n",
    "\n",
    "The main result of `Calc_Resp()` function (method) is to compute the response matrices over time. This is stored into a 3D numpy array `data` of shape (tmax//dt+1, N, N). The \"+1\" is because the first time step is *t=0*. All subsequent results are obtained out of `Rmats.data`, either slicing the 3D array projecting along different axes, or by estimating metrics out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some results\n",
    "\n",
    "For example, visualize the response matrices at selected time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few response curves. \n",
    "# The responses of i = 2, ..., N to the stimulus at j = 1.\n",
    "\n",
    "plt.figure(figsize=(6.4,3))\n",
    "for i in range(1,N):\n",
    "    plt.plot(Rmats.tpoints, Rmats.data[:,i,0], label=f'1 $\\\\to$ {i+1}')\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "plt.ylabel( 'Pair-wise Response' )\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the pair-wise response matrices at times t = 0.1, 0.3, 0.5, 1.0, 2.0, 3.0\n",
    "maxresp = Rmats.data.max()\n",
    "\n",
    "tidxlist = [10,20,50,100,200,500]\n",
    "plt.figure(figsize=[12,6])\n",
    "for i, tidx in enumerate(tidxlist):\n",
    "    t = tpoints[tidx]\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.title( f'$\\mathcal{{R}}(t)$ matrix at t={t:1.1f}' )\n",
    "    plt.imshow(Rmats.data[tidx], cmap=new_Reds)\n",
    "    \n",
    "    plt.clim(0,maxresp)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.yticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.xlabel( 'source node' )\n",
    "    plt.ylabel( 'target node' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Slicing and projecting `Rmats.data`\n",
    "\n",
    "Once the main tensor $\\mathcal{R}_{ij}(t)$ has been calculated, the rest of the analysis consists of extracting information from here in the form of metrics. BUT, also we will extract two types of projections from this tensor, to which we apply some of the same methods. \n",
    "\n",
    "1. The **global response** $R(t)$ is the projection of $\\mathcal{R}_{ij}(t)$ along both \"spatial\" axes, i *and* j. Therefore, the result is a 1D ndarray of length `nsteps`. This should be calculated using method (or function, see code options below) `GlobalResponse()`. The output `Rglob` is another object which inherits `tfinal`, `dt`, `tpoints`, `nsteps` from `Rmats`. And `Rglob.data` will be the 1D ndarray (time-series).\n",
    "\n",
    "2. The **node-wise responses** $r_i(t)$ is the projection of $\\mathcal{R}_{ij}(t)$ along one of the spatial axes (i or j). This should be calculated with a method (or function, see code options below) called `NodeResponses()`. The result, `r_nodes`, is another object which inherits `tfinal`, `dt`, `tpoints`, `nsteps` and `labels` (of the nodes) from `Rmats`. The numerical result `r_nodes.data` is a 2D ndarray of shape (`nsteps`,`N`).\n",
    "\n",
    "In next cell, some pseudo-code of how we would call these two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global network response\n",
    "## `Rglob` is an object which inherits `tpoints`, `dt`, etc.\n",
    "Rglob = Rmats.GlobalResponse()  # or better ...\n",
    "Rglob = sna.GlobalResponse(Rmats)   # MG: I WOULD GO FOR THIS OPTION, WITH CHECK ON OBJET Rmats THAT METHOD MAKES SENSE\n",
    "\n",
    "# Print some feedback\n",
    "print( Rglob.data.shape )  # `Rglob.data` is a 1D array (time-series)\n",
    "print( Rglob.tfinal )\n",
    "print( Rglob.nsteps )\n",
    "\n",
    "# Plot the global response curve, r(t)\n",
    "plt.figure()\n",
    "plt.plot(Rglob.tpoints, Rglob.data)\n",
    "plt.xlabel( 'Time (a.u.)' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the node-wise responses\n",
    "## `r_nodes` is an object which inherits the temporal attributes of Rmats + Rmats.labels  \n",
    "# If network `con` is directed, we get two results (input and output properties)\n",
    "if Rmats.directed:\n",
    "    inr_nodes, outr_nodes = Rmats.NodeResponses(selfresp=True)  # or prefered ...\n",
    "    inr_nodes, outr_nodes = sna.NodeResponses(Rmats, selfresp=True)\n",
    "# if network  `con` is undirected, we only get one result \n",
    "else:\n",
    "    r_nodes = Rmats.NodeResponses(selfresp=True)   # or prefered ...\n",
    "    r_nodes = sna.NodeResponses(Rmats, selfresp=True)\n",
    "\n",
    "# Print some feedback \n",
    "print( r_nodes.data.shape )\n",
    "print( r_nodes.tfinal )\n",
    "\n",
    "# Plot all the node responses\n",
    "plt.figure()\n",
    "for i in range(N):\n",
    "    plt.plot(inr_nodes.tpoints, inr_nodes.data[i])\n",
    "plt.xlabel( 'Time (a.u.)' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting further metrics\n",
    "\n",
    "So far, we have computed three \"*time-series*\" objects, `Rmats`, `r_nodes` and `globR` of dimensions 3D (time,N,N), 2D (time,N) and 1D (time,) respectively. From here, the idea is to extract more metrics out of them. For example, the total reponses and the time-to-peak. In the current (v1) version, these are computed in `sna.AreaUnderCurve()` and `sna.Time2Peak()`. At this moment, these two functions accept arrays of 3D, 2D or 1D as input and will do the same calculations on them. As result, the output of both functions are a 2D matrix (N,N), a 1D array (N,) and a scalar number, respectively. \n",
    "\n",
    "Ideally, we would like the input/output to work in the same way as it does now, such that we can still call for example:\n",
    "\n",
    "- `totR = sna.AreaUnderCurve(Rmats)` is a 2D matrix, ndarray of shape (N,N),\n",
    "- `totr_nodes = sna.AreaUnderCurve(r_nodes)` is a 1D ndarray of shape (N,), and\n",
    "- `totRglob = sna.AreaUnderCurve(Rglob)` is a scalar number.\n",
    "\n",
    "Results `totR`, `totr_nodes` and `totRglob` are no longer objects. In principle, they don't need to carry metadata. The calculation of `AreaUnderCurve()` and `Time2Peak()` require also the `dt`, which will be read directly from the input objects. In v1 of the library, we need to pass `dt` manually, and that sucks.\n",
    "\n",
    "So, here some possible pseudo-code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the time-to-peak between all pair of nodes\n",
    "ttpR = Rmats.Time2Peak()  # Or prefered ...\n",
    "ttpR = sna.Time2Peak(Rmats)\n",
    "\n",
    "# Visualize the ttp matrix\n",
    "plt.figure()\n",
    "plt.title( 'Time-to-peak distance' )\n",
    "plt.imshow(ttpR)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "# Compute the total node responses\n",
    "totinr_nodes = inr_nodes.AreaUnderCurve()  # or prefered ...\n",
    "totinr_nodes = sna.AreaUnderCurve(inr_nodes)\n",
    "\n",
    "totoutr_nodes = outr_nodes.AreaUnderCurve()   # or prefered ...\n",
    "totoutr_nodes = sna.AreaUnderCurve(outr_nodes)\n",
    "\n",
    "print( totinr_nodes.data.shape )   # `data` is the 2D array\n",
    "\n",
    "# Plot the relation between the input / output node relations\n",
    "maxr = max(totinr_nodes.max(), totoutr_nodes.max())\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(totinr_nodes, totoutr_nodes)\n",
    "plt.plot((0,0), (maxr,maxr), ls='--', color='gray')  # refer\n",
    "plt.xlabel( 'Total IN-response' )\n",
    "plt.ylabel( 'Total OUT-response' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some further results\n",
    "totRglob = Rglob.AreaUnderCurve()  # or bettet ...\n",
    "totRglob = sna.AreaUnderCurve(Rmats)                              \n",
    "\n",
    "# MG: WE CAN CHECK THE dt OF THE OBJECT Rmats (AND FOR E.G. DISCRETE CASCADE SET dt=1)\n",
    "def AreaUnderCurve(rmat, type=xxx): # with xxx = 'global', 'in', 'out', 'conn'\n",
    "\n",
    "    if type(Rmat) in [sna.DiscreteCascade, sna.ContinuousCascade]:\n",
    "        raise ValueError('AreaUnderCurve for diverging response doesnt make sense...') # or just warning???\n",
    "    if type(Rmat) in [sna.RandomWalk]:\n",
    "        raise ValueError('AreaUnderCurve for saturating response doesnt make sense...') # or just warning???\n",
    "    if type(Rmat) in [sna.LeakyCascade]:\n",
    "        if type=='global':\n",
    "            return rmat.data.sum(axis=(0,1,2))\n",
    "        elif type=='in':\n",
    "            return rmat.data.sum(axis=(0,2))\n",
    "        elif type=='out':\n",
    "            return rmat.data.sum(axis=(0,1))\n",
    "        elif type=='conn':\n",
    "            return rmat.data.sum(axis=(0))\n",
    "        else:\n",
    "            raise ValueError('unknown type')\n",
    "\n",
    "gr = sna.GlobalResponse(Rmat)\n",
    "plt.plot(Rmat.tpoints, gr)\n",
    "\n",
    "\n",
    "# OR WE CAN HAVE A FUNCTION THAT IS INHERITED  BUT BLOCKED FOR SOME CLASSES\n",
    "\n",
    "def RMAT():\n",
    "    def __init__():\n",
    "        self.data = None\n",
    "    \n",
    "    def AreaUnderCurve(type=xxx):\n",
    "        if type=='global':\n",
    "            return self.data.sum(axis=(0,1,2))\n",
    "        elif type=='in':\n",
    "            return self.data.sum(axis=(0,2))\n",
    "        elif type=='out':\n",
    "            return self.data.sum(axis=(0,1))\n",
    "        elif type=='conn':\n",
    "            return self.data.sum(axis=(0))\n",
    "\n",
    "def DiscreteCascade(RMAT):\n",
    "\n",
    "    def AreaUnderCurve():\n",
    "        raise ValueError('doesnt make sense!!!')\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "ttp_Rglob = Rglob.Time2Peak()      # Already knows `dt`, inherited it \n",
    "ttp_Rglob = sna.Time2Peak(Rglob)   # ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
