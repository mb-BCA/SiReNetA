{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-code discussion towards v2\n",
    "\n",
    "Authors: **Gorka Zamora-López** and **Matthieu Gilson**\n",
    "\n",
    "---------------------\n",
    "\n",
    "The goal of this notebook is to try, propose and discuss how we would like that typical workflows look like in the object-oriented version of *SiReNetA* (v2). The notebook is based on the workflow described in the first tutorial [notebook](https://github.com/mb-BCA/SiReNetA_Tutorials/blob/master/Tutorial_Notebooks/1_GettingStarted.ipynb).\n",
    "\n",
    "See also further discussions in the [TODO_Future.md](https://github.com/mb-BCA/SiReNetA/blob/v1_dev/TODO_Future.md) file.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard & third-party library imports\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sireneta as sna\n",
    "print( 'SiReNetA:', sna.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting options to control visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the options from a local file\n",
    "from plot_specs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the network determined by the following binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample graph to study\n",
    "net = np.loadtxt('../Data/Testnet_N8.txt', dtype=int)\n",
    "# Number of nodes\n",
    "N = len(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence of the leaky-cascade model depends on the leakage time-constant, when $\\tau \\leq 1 \\,/\\, \\lambda_{max}$. Find the largest eigenvalue of connectivity *A* and the critical $\\tau_{max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest eigenvalue of the connectivity matrix A\n",
    "evs = np.linalg.eigvals(net)\n",
    "evmax = evs.real.max()\n",
    "# Calculate the largest possible tau\n",
    "taumax = 1.0 / evmax\n",
    "\n",
    "print( f'Spectral radius:\\t{evmax:2.5f}' )\n",
    "print( f'Largest possible tau:\\t{taumax:2.5f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Initialize the main container object (instance)\n",
    "\n",
    "Object `Rmats` must be initialized with two mandatory parameters:\n",
    "\n",
    "* `con` : The connectivity matrix.\n",
    "* `canmod` : identifier for the canonical model. Probably a string.\n",
    "\n",
    "These two parameters shall be **_unmutable_**. They cannot be changed after object creation. `con` will be a connectivity matrix, either loaded from data or generated with some graph library.\n",
    "\n",
    "\n",
    "> WARNING ! `con` is likely to be generated by a graph analysis software, or loaded from data as \n",
    "\n",
    "**Gorka**: I don't think we need to initialize `Rmats` with more parameters.\n",
    "\n",
    "TODO : Probably, find a better name for the creation function `PairWiseResp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rmat must be initialized for a connectivity matrix and a canonical model.\n",
    "# These are unmutable and cannot be changed. Ever !\n",
    "Rmats = sna.PairWiseResp(con=net.T, canmod='LeakyCascade')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, `Rmats` should also *know* whether `con` is directed or undirected and the number of nodes *N*. E.g.:\n",
    "\n",
    "``` python\n",
    ">>> Rmats.N\n",
    "8\n",
    ">>> Rmats.directed\n",
    "False\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the conditions and compute the pair-wise responses\n",
    "\n",
    "For now, I see two ways in which the needed metadata could be inputed into the `Rmats` object and compute the pair-wise responses.\n",
    "\n",
    "----------------------\n",
    "\n",
    "### Option 1: Feed `Rmats` with parameters and then call the calculation of $\\mathcal{R}_{ij}(t)$.\n",
    "In this option, the `Rmats` object is first populated with all the parameters needed for the \"simulation\" (feed the necessary attributes) and then the pair-wise responses are calculated.\n",
    "\n",
    "1. Feed the different parameters (attributes) to `Rmats`, e.g.:\n",
    "    - `Rmats.max = 10`\n",
    "    - `Rmats.tau = 0.8 * taumax`\n",
    "    - ...\n",
    "2. Calculate the pairwise responses `Rmats.Calc_Resp()`\n",
    "\n",
    "I think this is quite a traditional way, although not my favourite choice (Gorka) because it is not flexible in case the \"simulation\" needs to be run again, e.g. because the `tmax` was not long enough and responses didn't converge enough. See *Option 2* and the discussion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "Rmats.tmax = 10\n",
    "Rmats.timestep = 0.01\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "# NOTE: Actually, `taumax` should also be an attribute of Rmats, right?\n",
    "Rmats.tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "# Example of stimulus on one node\n",
    "Rmats.S0 = np.zeros(N)\n",
    "Rmats.S0[0] = 1.0\n",
    "\n",
    "# Example of all nodes receive same stimulus\n",
    "Rmats.S0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal evolution of the pair-wise responses R(t)\n",
    "Rmats.Calc_Resp(case='regressed') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this option, all the parameters needed for the \"simulation\" have been already stored as attributes of `Rmats`, before calling the `Calc_Resp()` function.\n",
    "These are: `S0`, `tmax`, `timestep` and `tau`. Parameter `case` is rather optional and only available in two of the five canonical models. `case` could be stored before calling the function, or added as an attribute to `Rmats` at function call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "### Option 2: Define the parameters externally, and then call the calculation of $\\mathcal{R}_{ij}(t)$.\n",
    "In this option, the \"simulation\" parameters are defined in a more traditional way (non-OO). The parameters are defined and explicitly entered into the `Calc_Resp()` function. It is only when `Calc_Resp()` is called, that the attributes of `Rmats` are populated or updated.\n",
    "\n",
    "1. Feed the different parameters (attributes) to `Rmats`, e.g.:\n",
    "    - `tfinal = 10 10`\n",
    "    - `dt = 0.01` \n",
    "    - `tau = 0.8 * taumax`\n",
    "    - `stimvec = np.ones(N)` \n",
    "2. Calculate the pairwise responses `Rmats.Calc_Resp(S0=stimvec, tmax=tfinal, timestep=dt, case='regressed')`.\n",
    "\n",
    "I think this is quite a traditional way, although not my favourite choice (Gorka) because it is not flexible in case the \"simulation\" needs to be run again, e.g. because the `tmax` was not long enough and responses didn't converge enough. See *Option 2* and the discussion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"simulation\" parameters\n",
    "# Set the temporal resolution\n",
    "tfinal = 10\n",
    "dt = 0.01\n",
    "\n",
    "# Set the leakage time-constants τ, proportional to taumax\n",
    "tau = 0.8 * taumax\n",
    "\n",
    "# Define the stimulation amplitude to every node\n",
    "stimvec = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal evolution of the pair-wise responses R(t)\n",
    "## Here, all necessary \"simulation\" parameters (`S0`, `tmax`, `timestep` and `tau`)\n",
    "## shall be manually entered. `case`is an optional parameter.\n",
    "Rmats.calc_Resp(S0=stim, tau=tau, tmax=tfinal, timestep=dt, case='regressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this option, the crucial parameters needed for the \"simulation\" (`S0`, `tmax`, `timestep` and `tau`) need to be entered to `Calc_Resp()` explicitely. Then, when the function is called, the function fills or updates those attributes into `Rmats` object. \n",
    "\n",
    "Q : Actually, is there a way in Python to prevent that a user externally updates attributes `S0`, `tmax`, `timestep` and `tau`, and that these can **only** be updated from inside `Calc_Resp()` function ? That would make things pretty safe.\n",
    "\n",
    "----------------------\n",
    "\n",
    "**Gorka** : Why do I prefer this option? I think it is safer that the crucial metadata will not be changed accidentally by the user or anything else. For example, attribures `tmax` and `timestep` are not directly modified by the user, but are only updated when calling the `Calc_Resp()` function. \n",
    "\n",
    "Imagine we compute the responses for tmax = 10 and timestep = 0.1. We plot the result and realize that this temporal scale is too large. We want to recalculate the responses (without having to initialize a new instance) for tmax = 1.0 and timestep=0.001.\n",
    "In Option-1 that would mean to edit manually the attributes `Rmats.tmax=1.0` and `Rmats.timestep=0.001`. Then, we have to deliberatelly call again `Rmats.Calc_Resp()` in order to update the results. But, what if the user, after changing `tmax` and `timestep` attributes, forget to call `Calc_Resp()` ? In that case, the metadata of `Rmats` does no longer match the one used to previously compute the responses, whose result is still saved into an array of shape (10//0.1+1,N,N), instead of the (1.0//0.001+1,N,N) now expected. This situation might not be very usual when scripting but … I can easily see things like this happening when working on Jupyter Notebooks.\n",
    "\n",
    "In Option-2, the only time that attributes are allowed to change are at the call of `Calc_Resp()` function, and only this function has the permission to change them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of `Calc_Resp()` function\n",
    "\n",
    "The main result of `Calc_Resp()` function (method) is to compute the response matrices over time. This is stored into a 3D numpy array `data` of shape (tmax//dt+1, N, N). The \"+1\" is because the first time step is *t=0*. All subsequent results are obtained out of `Rmats.data`, either slicing the 3D array projecting along different axes, or by estimating metrics out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some results\n",
    "\n",
    "For example, visualize the response matrices at selected time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the pair-wise response matrices at times t = 0.1, 0.3, 0.5, 1.0, 2.0, 3.0\n",
    "maxresp = Rmats.max()\n",
    "\n",
    "tidxlist = [10,20,50,100,200,500]\n",
    "plt.figure(figsize=[12,6])\n",
    "for i, tidx in enumerate(tidxlist):\n",
    "    t = tpoints[tidx]\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.title( f'$\\mathcal{{R}}(t)$ matrix at t={t:1.1f}' )\n",
    "    plt.imshow(Rmats.data[tidx], cmap=new_Reds)\n",
    "    \n",
    "    plt.clim(0,maxresp)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.yticks(np.arange(N), np.arange(N)+1)\n",
    "    plt.xlabel( 'source node' )\n",
    "    plt.ylabel( 'target node' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few response curves. \n",
    "# The responses of i = 2, ..., N to the stimulus at j = 1.\n",
    "\n",
    "plt.figure(figsize=(6.4,3))\n",
    "for i in range(1,N):\n",
    "    plt.plot(Rmats.tpoints, Rmats.data[:,i,0], label=f'1 $\\\\to$ {i+1}')\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "plt.ylabel( 'Pair-wise Response' )\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Slicing and projecting `Rmats.data`. Extracting metrics.\n",
    "\n",
    "I have a major doubt here. After the tensor containing $\\mathcal{R}_{ij}(t)$, the other two time-series \"arrays\" are the global response $R(t)$ and the pair-wise responses $r_i(t)$. `Rglob` is a 1D ndarray of length `nsteps` and `rnodes` is a 2D ndarray of shape (`nsteps`,`N`).\n",
    "\n",
    "The question is whether `Rglob` and `rnodes` \n",
    "1. should be themselves two independent objects which inherit the temporal attributes from `Rmats`, and the methods (e.g., `Time2Peak()` and `AreaUnderCurve()`) or \n",
    "2. they should be directly considered attributes of `Rmats`. Q: Can attributes be objects themselves, that share selected attributes?  \n",
    "\n",
    "Personally, I would have a preference for the first case but, for mainly because that would allow me to keep the the workflows closer to what I am used to. But I ignore the details of what would be easier and more consistent to code internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider them **as independent objects**, we would for example do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global network response\n",
    "Rglob = sna.GlobalResponse(Rmats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, the largest (*and fastest* !) responses correspond to *i = 2, 3* which are directly connected to *j = 1*, followed by *4* and *6* which are the nodes with more connections in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 …\n",
    "\n",
    "… is finally to _**extract network metrics out of**_ $\\mathcal{R}\\_{ij}(t)$, in the form of spatio-temporal properties of the response propagation. There are many such metrics that could be derived. Here we only estimate two for illustration (see [Calculating Response to Stimulus and Metrics](2_Basics_StimRespMetrics.ipynb) for further metrics):\n",
    "\n",
    "\n",
    "- Time-to-peak distance $D^{ttp}_{ij}$, which analogous to the graph distance, and …\n",
    "- the total node responses, $\\bar{r}_i$, which is reminiscent of the degree or centrality of a node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pair-wise responses $\\mathcal{R}_{i \\gets 1}(t)$ plotted above showed that every pair-wise interaction peaks at different times $t^*_{i1}$. This pair-wise time-to-peak can be employed to redefine the distance between nodes in a network ($D^{ttp}_{ij} = t^*_{ij}$) and thus  generalize the usual path distance in graphs. See [Network Distance](5_UseCase_NetDist.ipynb) and [Zamora-López & Gilson, Chaos (2024)](https://doi.org/10.1063/5.0202241) for further details.\n",
    "\n",
    "In the following we compute and visualize this distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the time-to-peak distance \n",
    "ttpdist = sna.Time2Peak(Rmats, timestep=dt)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "# Plot the adjacency matrix\n",
    "plt.subplot(1,2,1)\n",
    "plt.title( 'Adjacency matrix' )\n",
    "plt.imshow(net, cmap='gray_r')\n",
    "plt.colorbar()\n",
    "plt.xlabel( 'Node index' )\n",
    "plt.ylabel( 'Node index' )\n",
    "\n",
    "# Plot the time-2-peak distance matrix\n",
    "plt.subplot(1,2,2)\n",
    "plt.title( 'Time-to-peak distance' )\n",
    "plt.imshow(ttpdist)\n",
    "plt.colorbar()\n",
    "plt.xlabel( 'Node index' )\n",
    "plt.ylabel( 'Node index' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected from the $\\mathcal{R}_{i \\gets 1}(t)$ curves above, the nodes that are directly connected peak earlier to the stimuli and are thus \"closer\".\n",
    "\n",
    "Finally, we compute the total node responses $\\bar{r}_i$. For that, we first compute the (summed) response $r_i(t)$ of *i* to the stimuli in all other *j*. Then $\\bar{r}_i$ is the accumulated response of *i* over time (integral or area-under-the-curve of $r_i(t)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualise the node responses\n",
    "r_nodes = sna.NodeResponses(Rmats)[0]\n",
    "\n",
    "# Visualize the node responses over time\n",
    "plt.figure(figsize=(6.4,3.8))\n",
    "for i in range(N):\n",
    "    plt.plot(tpoints, r_nodes[:,i], label=f'Node {i+1}')\n",
    "plt.plot(tpoints, Rglob / N, label='Global', c='gray', ls='--', lw=4)\n",
    "plt.xlabel( 'Time (a.u.)' )\n",
    "plt.ylabel( 'Node Response' )\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes *i = 4* and *6* are those with largest responses, since they are the most connected. On the contrary, *i = 5* and *7* have only one connection and thus display the smallest responses.\n",
    "\n",
    "We now reduce this into one value per node, the total node response $\\bar{r}_i$ and compare to their degrees $k_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the total node responses\n",
    "totr_nodes = sna.AreaUnderCurve(r_nodes, dt)\n",
    "\n",
    "# Visualize the total node responses\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(N):\n",
    "    plt.bar((i+1), totr_nodes[i])\n",
    "plt.xlabel( 'Node index' )\n",
    "plt.ylabel( 'Total node resp.  $\\\\bar{r}_i$' );\n",
    "\n",
    "# Visualize their relation with the degree\n",
    "deg = net.sum(axis=0)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(N):\n",
    "    plt.scatter(deg[i], totr_nodes[i])\n",
    "plt.xlabel( 'Degree of node, $k_i$' )\n",
    "plt.ylabel( 'Total node resp.  $\\\\bar{r}_i$' )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we can explore _**the relation between the centrality of a node and their total response**_. \n",
    "\n",
    "In classical graph theory, the degree of a node is a first-order measure of centrality. The  closeness centrality $c_i$ is defined as the sum of (geodesic) distances from node *i* to the others: $c_i = \\sum_{k=1}^N D_{ik}$. Both degree and closeness centrality are typically related via a negative correlation: the more connected a node (like a hub), the closer it is on average to other nodes via network paths.\n",
    "\n",
    "Analogously, closeness centrality can be defined from the time-to-peak distance matrix as $c_i = \\sum_{k=1}^N  D^{ttp}_{ik}$. Below, we compare this closeness centrality with the degree and the total node responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute closeness centrality from time-to-peak distances\n",
    "c_nodes = ttpdist.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "# Compare centrality with degree\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(N):\n",
    "    plt.scatter(deg[i],c_nodes[i])\n",
    "plt.xlabel( 'Degree of Node, $k_i$' )\n",
    "plt.ylabel( 'Closeness cent.' )\n",
    "\n",
    "# Compare centrality with total node responses\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(N):\n",
    "    plt.scatter(totr_nodes[i],c_nodes[i])\n",
    "plt.xlabel( 'Total node resp.  $\\\\bar{r}_i$' )\n",
    "plt.ylabel( 'Closeness cent.')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the expected negative correlations in both figures, the second one following because the degree and the total response are positively correlated. This shows that, for this example small network, nodes that have high degree (a local property) are also those \"important\" for the centrality (a global property that takes the whole network into account).\n",
    "\n",
    "Note that the claimed correspondance between geodesic distance and time-to-peak is valid **because the considered network is binary = unweighted**. However, the dynamical measures here proposed are also straight-forwardly applicable to weighted networks, unlike many graph metrics: for instance, a weight could correspond to a cost (like with the geodesic distance) or an efficacy to propagate the signal. Care must thus be taken when applying and interpreting spatio-temporal measures applied to a particular network. See [Weighted Networks](6_Basics_WeightedNets.ipynb) for examples of the applications to weighted cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
